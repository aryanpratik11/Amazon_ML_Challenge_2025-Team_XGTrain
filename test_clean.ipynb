{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14800820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5f391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned, sorted Units standardized and replaced CSV saved to: test_clean1.csv\n"
     ]
    }
   ],
   "source": [
    "# Paths to your files\n",
    "input_csv = \"test.csv\"    # change to your file path\n",
    "output_csv = \"test_clean1.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Function to extract Value and Unit\n",
    "def extract_value_unit(text):\n",
    "    # Extract Value\n",
    "    value_match = re.search(r\"Value:\\s*([\\d\\.]+)\", text)\n",
    "    value = float(value_match.group(1)) if value_match else None\n",
    "\n",
    "    # Extract Unit\n",
    "    unit_match = re.search(r\"Unit:\\s*([\\w\\s]+)\", text)\n",
    "    unit = unit_match.group(1).strip() if unit_match else None\n",
    "\n",
    "    # Remove Value and Unit lines from catalog_content\n",
    "    text_clean = re.sub(r\"Value:\\s*[\\d\\.]+\\s*\", \"\", text)\n",
    "    text_clean = re.sub(r\"Unit:\\s*[\\w\\s]+\\s*\", \"\", text_clean)\n",
    "\n",
    "    return pd.Series([value, unit, text_clean])\n",
    "\n",
    "# Apply extraction\n",
    "df[['value', 'unit', 'catalog_content']] = df['catalog_content'].apply(extract_value_unit)\n",
    "\n",
    "# Convert unit to lowercase\n",
    "df['unit'] = df['unit'].str.lower()\n",
    "\n",
    "# Mapping of unit variants ‚Üí standard unit and conversion factor\n",
    "unit_mapping = {\n",
    "    # Weight variants\n",
    "    'oz': ('ounce', 1),\n",
    "    'ounce': ('ounce', 1),\n",
    "    'ounces': ('ounce', 1),\n",
    "    'lb': ('ounce', 16),\n",
    "    'pound': ('ounce', 16),\n",
    "    'pounds': ('ounce', 16),\n",
    "    'g': ('ounce', 0.03527396),\n",
    "    'gram': ('ounce', 0.03527396),\n",
    "    'grams': ('ounce', 0.03527396),\n",
    "    'kg': ('ounce', 35.27396),\n",
    "    'gramm': ('ounce', 0.03527396),\n",
    "\n",
    "    # Volume variants\n",
    "    'fl oz': ('fl oz', 1),\n",
    "    'fl ounce': ('fl oz', 1),\n",
    "    'floz': ('fl oz', 1),\n",
    "    'fluid ounce': ('fl oz', 1),\n",
    "    'fluid ounces': ('fl oz', 1),\n",
    "    'ml': ('fl oz', 0.033814),\n",
    "    'millilitre': ('fl oz', 0.033814),\n",
    "    'milliliter': ('fl oz', 0.033814),\n",
    "    'mililitro': ('fl oz', 0.033814),\n",
    "    'millilitro': ('fl oz', 0.033814),\n",
    "    'milliliters': ('fl oz', 0.033814),\n",
    "    'liters': ('fl oz', 33.814),\n",
    "    'liter': ('fl oz', 33.814),\n",
    "    'l': ('fl oz', 33.814),\n",
    "    'ltr': ('fl oz', 33.814),\n",
    "    'fl': ('fl oz', 1),  # approximate, depends on context\n",
    "\n",
    "    # Count / each\n",
    "    'ct': ('count', 1),\n",
    "    'each': ('count', 1),\n",
    "    'piece': ('count', 1),\n",
    "    'pieces': ('count', 1),\n",
    "\n",
    "    'pack': ('packs', 1)\n",
    "}\n",
    "\n",
    "# Function to standardize unit and adjust value\n",
    "def standardize_unit(row):\n",
    "    unit = str(row['unit']).lower().strip()\n",
    "    value = row['value']\n",
    "    \n",
    "    if unit in unit_mapping:\n",
    "        standard_unit, factor = unit_mapping[unit]\n",
    "        new_value = value * factor\n",
    "        return pd.Series([standard_unit, new_value])\n",
    "    else:\n",
    "        # Keep unknown units as-is\n",
    "        return pd.Series([unit, value])\n",
    "\n",
    "# Apply standardization and directly replace columns\n",
    "df[['unit', 'value']] = df.apply(standardize_unit, axis=1)\n",
    "\n",
    "# Save cleaned and sorted CSV\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Cleaned, sorted Units standardized and replaced CSV saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da803a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit counts and parity:\n",
      "ounce: 44173\n",
      "count: 18253\n",
      "fl oz: 11436\n",
      "none: 1011\n",
      "packs: 36\n",
      "bottle: 9\n",
      "bag: 7\n",
      "1: 6\n",
      "box: 5\n",
      "product_weight: 5\n",
      "foot: 4\n",
      "tea bags: 4\n",
      "jar: 4\n",
      "packet: 3\n",
      "k: 3\n",
      "paper cupcake liners: 3\n",
      "ea: 3\n",
      "sq ft: 2\n",
      "lbs: 2\n",
      "per package: 2\n",
      "pac: 2\n",
      "gallon: 2\n",
      "na: 1\n",
      "kit: 1\n",
      "200 capsules: 1\n",
      "fluid_ounces: 1\n",
      "16 ounces: 1\n",
      "2: 1\n",
      "container: 1\n",
      "sachet: 1\n",
      "unit: 1\n",
      "0: 1\n",
      "m: 1\n",
      "tin: 1\n",
      "case: 1\n",
      "jars: 1\n",
      "gallons: 1\n",
      "cou: 1\n",
      "sugar substitute: 1\n",
      "pouch: 1\n",
      "capsules: 1\n",
      "st√ºck: 1\n",
      "comes as a single dispenser unit with 1 count of candy refills\n",
      "bullet point 5: 1\n",
      "12: 1\n",
      "16: 1\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned CSV\n",
    "csv_file = \"test_clean1.csv\"  # your cleaned file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Count occurrences of each unit\n",
    "unit_counts = df['unit'].dropna().value_counts()\n",
    "\n",
    "print(\"Unit counts and parity:\")\n",
    "for unit, count in unit_counts.items():\n",
    "    print(f\"{unit}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add4fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_clean2.csv saved with the new column order!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"test_clean1.csv\")\n",
    "\n",
    "# Function to extract IPQ from catalog_content\n",
    "def extract_ipq(text):\n",
    "    if pd.isna(text):\n",
    "        return 1  # default to 1 if not found\n",
    "\n",
    "    # Common patterns for pack quantity\n",
    "    patterns = [\n",
    "        r'pack of (\\d+)',          # \"Pack of 10\"\n",
    "        r'(\\d+)\\s*packs',         # \"10 packs\"\n",
    "        r'packs?\\s*(\\d+)',        # \"packs 10\" or \"pack 10\"\n",
    "        r'(\\d+)\\s*per pack',      # \"12 per pack\"\n",
    "        r'(\\d+)\\s*per case',      # \"12 per case\"\n",
    "        r'(\\d+)\\s*pack',          # \"10 pack\"\n",
    "        r'(\\d+)\\s*count',         # \"20 count\"\n",
    "        r'(\\d+)\\s*pieces',        # \"240 pieces\"\n",
    "        r'(\\d+)\\s*packet',        # \"24 packets\"\n",
    "        r'(\\d+)[-/]carton',       # \"6/carton\" or \"6-carton\"\n",
    "        r'case\\s*(\\d+)',          # \"case 6\"\n",
    "    ]\n",
    "    \n",
    "    for pat in patterns:\n",
    "        match = re.search(pat, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return 1  # default to 1 if nothing matches\n",
    "\n",
    "# Function to extract item_name and specification\n",
    "def extract_fields(text):\n",
    "    if pd.isna(text):\n",
    "        return pd.Series({'item_name': None, 'specification': None})\n",
    "    \n",
    "    # Item Name\n",
    "    item_match = re.search(r'Item Name:\\s*(.*?)(?:\\n|$)', text)\n",
    "    item_name = item_match.group(1).strip() + '\\n' if item_match else None\n",
    "    \n",
    "    # Specification (combine bullet points and product description)\n",
    "    bullets = re.findall(r'Bullet Point \\d+:\\s*(.*?)(?:\\n|$)', text)\n",
    "    bullet_text = \" \".join([b.strip() for b in bullets]) if bullets else \"\"\n",
    "    \n",
    "    desc_match = re.search(r'Product Description:\\s*(.*?)(?:\\n|$)', text)\n",
    "    desc_text = desc_match.group(1).strip() if desc_match else \"\"\n",
    "    \n",
    "    # Combine bullet points and description into specification\n",
    "    specification = (bullet_text + \" \" + desc_text).strip() + '\\n' if (bullet_text or desc_text) else None\n",
    "    \n",
    "    return pd.Series({'item_name': item_name, 'specification': specification})\n",
    "\n",
    "# Apply extraction\n",
    "df['ipq'] = df['catalog_content'].apply(extract_ipq)\n",
    "parsed_cols = df['catalog_content'].apply(extract_fields)\n",
    "df = pd.concat([df, parsed_cols], axis=1)\n",
    "\n",
    "# Define the desired column order\n",
    "column_order = [\n",
    "    'sample_id',\n",
    "    'item_name',\n",
    "    'specification',\n",
    "    'ipq',\n",
    "    'unit',\n",
    "    'value',\n",
    "    'image_link',\n",
    "    'catalog_content'\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df = df[column_order]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"test_clean2.csv\", index=False)\n",
    "\n",
    "# Confirmation\n",
    "print(\"test_clean2.csv saved with the new column order!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c9573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sample_id', 'item_name', 'specification', 'ipq', 'unit', 'value',\n",
      "       'image_link', 'catalog_content'],\n",
      "      dtype='object')\n",
      "sample_id              0\n",
      "item_name              8\n",
      "specification      13707\n",
      "ipq                    0\n",
      "unit                   2\n",
      "value               1011\n",
      "image_link             0\n",
      "catalog_content        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test_clean2.csv\")\n",
    "print(test_df.columns)\n",
    "print(test_df.isnull().sum())  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03dd023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_17672\\784390163.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['item_name'].fillna('', inplace=True)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_17672\\784390163.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['specification'].fillna('', inplace=True)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_17672\\784390163.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['catalog_content'].fillna('', inplace=True)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_17672\\784390163.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['unit'].fillna('unknown', inplace=True)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_17672\\784390163.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['value'].fillna(test_df['value'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = text.lower().strip()  # Lowercase and remove extra spaces\n",
    "    text = text.replace('\\n', ' ')  # Replace newlines with spaces\n",
    "    return text\n",
    "\n",
    "for col in ['item_name', 'specification', 'catalog_content']:\n",
    "    test_df[col] = test_df[col].apply(clean_text)\n",
    "\n",
    "# Text columns\n",
    "test_df['item_name'].fillna('', inplace=True)\n",
    "test_df['specification'].fillna('', inplace=True)\n",
    "test_df['catalog_content'].fillna('', inplace=True)\n",
    "\n",
    "test_df['unit'].fillna('unknown', inplace=True)\n",
    "\n",
    "test_df['value'].fillna(test_df['value'].median(), inplace=True)\n",
    "\n",
    "test_df.to_csv(\"test_clean3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8edf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_clean4.csv saved with only item_name and specification!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"test_clean1.csv\")\n",
    "\n",
    "# Function to extract item_name and specification\n",
    "def extract_fields(text):\n",
    "    if pd.isna(text):\n",
    "        return pd.Series({'item_name': None, 'specification': None})\n",
    "    \n",
    "    # Extract Item Name\n",
    "    item_match = re.search(r'Item Name:\\s*(.*?)(?:\\n|$)', text, re.IGNORECASE)\n",
    "    item_name = item_match.group(1).strip() if item_match else None\n",
    "    \n",
    "    # Remove the entire Item Name line from text\n",
    "    text_without_item_name = re.sub(r'Item Name:.*(?:\\n|$)', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove remaining tags (Bullet Points, Product Description)\n",
    "    specification_text = re.sub(\n",
    "        r'Bullet Point \\d+:|Product Description:', \n",
    "        '', \n",
    "        text_without_item_name, \n",
    "        flags=re.IGNORECASE\n",
    "    ).strip()\n",
    "    \n",
    "    return pd.Series({'item_name': item_name, 'specification': specification_text})\n",
    "\n",
    "# Apply extraction\n",
    "parsed_cols = df['catalog_content'].apply(extract_fields)\n",
    "df = pd.concat([df, parsed_cols], axis=1)\n",
    "\n",
    "# Drop the original catalog_content column\n",
    "df = df.drop(columns=['catalog_content'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"test_clean4.csv\", index=False)\n",
    "print(\"test_clean4.csv saved with only item_name and specification!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8146179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_clean4.csv saved with lowercase and cleaned text!\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV\n",
    "df = pd.read_csv(\"test_clean4.csv\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Keep only letters, numbers, and spaces; replace other chars with space\n",
    "    text = re.sub(r'[^a-z0-9 ]+', ' ', text)\n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to desired columns\n",
    "for col in ['item_name', 'specification']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "\n",
    "# Save cleaned CSV\n",
    "df.to_csv(\"test_clean4.csv\", index=False)\n",
    "print(\"test_clean4.csv saved with lowercase and cleaned text!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1200f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_clean5.csv saved with new 'quantity' column!\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned CSV\n",
    "df = pd.read_csv(\"test_clean4.csv\")\n",
    "\n",
    "# Define quantity regex patterns\n",
    "quantity_patterns = [\n",
    "    r'pack\\s*of\\s*(\\d+)',\n",
    "    r'(\\d+)\\s*packs?',\n",
    "    r'packs?\\s*(\\d+)',\n",
    "    r'(\\d+)\\s*per\\s*pack',\n",
    "    r'(\\d+)\\s*per\\s*case',\n",
    "    r'(\\d+)\\s*count',\n",
    "    r'(\\d+)\\s*ct',\n",
    "    r'(\\d+)\\s*pieces?',\n",
    "    r'(\\d+)\\s*pcs',\n",
    "    r'(\\d+)\\s*piece',\n",
    "    r'(\\d+)\\s*pc',\n",
    "    r'(\\d+)\\s*packet[s]?',\n",
    "    r'(\\d+)[-/]\\s*carton[s]?',\n",
    "    r'case\\s*(\\d+)',\n",
    "    r'pk[-\\s]*(\\d+)',\n",
    "    r'(\\d+)[-\\s]*pk',\n",
    "    r'(\\d+)\\s*x\\s*(\\d+)?',\n",
    "    r'(\\d+)\\s*bag[s]?',\n",
    "    r'(\\d+)\\s*box(?:es)?',\n",
    "    r'(\\d+)\\s*bottle[s]?',\n",
    "    r'(\\d+)\\s*can[s]?',\n",
    "    r'(\\d+)\\s*tube[s]?',\n",
    "    r'(\\d+)\\s*sachet[s]?',\n",
    "    r'(\\d+)\\s*roll[s]?',\n",
    "    r'(\\d+)\\s*pair[s]?',\n",
    "    r'(\\d+)\\s*set[s]?',\n",
    "    r'size[:\\s-]*(\\d+)',\n",
    "]\n",
    "\n",
    "# Function to extract quantity from item_name\n",
    "def extract_quantity(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    for pattern in quantity_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            # If pattern has two groups (like \"2 x 3\"), multiply them\n",
    "            if len(match.groups()) > 1 and match.group(2):\n",
    "                return int(match.group(1)) * int(match.group(2))\n",
    "            return int(match.group(1))\n",
    "    return None  # If nothing matches\n",
    "\n",
    "# Apply extraction\n",
    "df['quantity'] = df['item_name'].apply(extract_quantity)\n",
    "\n",
    "# Save to new CSV\n",
    "df.to_csv(\"test_clean5.csv\", index=False)\n",
    "print(\"test_clean5.csv saved with new 'quantity' column!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34f5c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_clean5.csv saved with proper column order!\n"
     ]
    }
   ],
   "source": [
    "column_order = [\n",
    "    'sample_id',\n",
    "    'item_name',\n",
    "    'specification',\n",
    "    'quantity',\n",
    "    'unit',\n",
    "    'value',\n",
    "    'image_link'\n",
    "]\n",
    "df = df[[col for col in column_order if col in df.columns]]\n",
    "df.to_csv(\"test_clean5.csv\", index=False)\n",
    "print(\"test_clean5.csv saved with proper column order!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff7182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 75000 rows, 7 columns\n",
      "Saved updated dataset ‚Üí test_clean7.csv\n",
      "\n",
      "üìä Summary:\n",
      "Filled weight_oz: 50875\n",
      "Filled volume_fl_oz: 9012\n",
      "Filled count: 75000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ Load the dataset\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"test_clean6.csv\")\n",
    "print(f\"Loaded data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ Initialize new columns\n",
    "# ============================================================\n",
    "df[\"weight_oz\"] = np.nan\n",
    "df[\"volume_fl_oz\"] = np.nan\n",
    "df[\"count\"] = np.nan\n",
    "\n",
    "# ============================================================\n",
    "# Weight units ‚Üí convert everything to ounces (oz)\n",
    "# ============================================================\n",
    "weight_units = {\n",
    "    \"oz\": 1.0, \"ounce\": 1.0, \"ounces\": 1.0,\n",
    "    \"lb\": 16.0, \"lbs\": 16.0, \"pound\": 16.0, \"pounds\": 16.0,\n",
    "    \"g\": 0.03527396, \"gram\": 0.03527396, \"grams\": 0.03527396, \"gramm\": 0.03527396,\n",
    "    \"kg\": 35.27396, \"kilogram\": 35.27396, \"kilograms\": 35.27396,\n",
    "    \"mg\": 3.5274e-5, \"milligram\": 3.5274e-5, \"milligrams\": 3.5274e-5,\n",
    "    \"stone\": 224.0, \"st\": 224.0,           # UK weight\n",
    "    \"ton\": 32000.0, \"tons\": 32000.0        # US short ton\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Volume units ‚Üí convert everything to fluid ounces (fl oz)\n",
    "# ============================================================\n",
    "volume_units = {\n",
    "    \"fl oz\": 1.0, \"floz\": 1.0, \"fluid ounce\": 1.0, \"fluid ounces\": 1.0, \"fl ounce\": 1.0,\n",
    "    \"ml\": 0.033814, \"milliliter\": 0.033814, \"millilitre\": 0.033814, \"mililitro\": 0.033814,\n",
    "    \"l\": 33.814, \"ltr\": 33.814, \"liter\": 33.814, \"litre\": 33.814, \"liters\": 33.814, \"litres\": 33.814,\n",
    "    \"gallon\": 128.0, \"gallons\": 128.0, \"gal\": 128.0,\n",
    "    \"pt\": 16.0, \"pint\": 16.0, \"pints\": 16.0,         # US pint\n",
    "    \"qt\": 32.0, \"quart\": 32.0, \"quarts\": 32.0,     # US quart\n",
    "    \"cup\": 8.0, \"cups\": 8.0,                        # US cup\n",
    "    \"tbsp\": 0.5, \"tablespoon\": 0.5, \"tablespoons\": 0.5,\n",
    "    \"tsp\": 0.1666667, \"teaspoon\": 0.1666667, \"teaspoons\": 0.1666667\n",
    "}\n",
    "\n",
    "count_keywords = [\n",
    "    \"pack\", \"packs\", \"set\", \"sets\", \"box\", \"boxes\",\n",
    "    \"carton\", \"cartons\", \"bottle\", \"bottles\",\n",
    "    \"can\", \"cans\", \"jar\", \"jars\",\n",
    "    \"tube\", \"tubes\", \"sheet\", \"sheets\",\n",
    "    \"piece\", \"pieces\", \"pcs\", \"count\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ Helper: Extract numeric value + unit from text\n",
    "# ============================================================\n",
    "def extract_value_unit(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None, None\n",
    "    text = text.lower()\n",
    "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*([a-zA-Z ]+)', text)\n",
    "    if match:\n",
    "        value, unit = match.groups()\n",
    "        return float(value), unit.strip()\n",
    "    return None, None\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ Pass 1: Use existing `value` and `units` columns (if exist)\n",
    "# ============================================================\n",
    "if \"value\" in df.columns and \"units\" in df.columns:\n",
    "    for i, row in df.iterrows():\n",
    "        val, unit = row[\"value\"], str(row[\"units\"]).lower()\n",
    "\n",
    "        # Weight units\n",
    "        for wu in weight_units:\n",
    "            if wu in unit:\n",
    "                df.at[i, \"weight_oz\"] = float(val) * weight_units[wu]\n",
    "                break\n",
    "\n",
    "        # Volume units\n",
    "        for vu in volume_units:\n",
    "            if vu in unit:\n",
    "                df.at[i, \"volume_fl_oz\"] = float(val) * volume_units[vu]\n",
    "                break\n",
    "\n",
    "        # Count (like 10 pack, 4 pcs)\n",
    "        if \"pack\" in unit or \"piece\" in unit or \"count\" in unit or \"pcs\" in unit:\n",
    "            df.at[i, \"count\"] = float(val)\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ Pass 2: Fill missing from `specification` and `item_name`\n",
    "# ============================================================\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row[\"weight_oz\"]) and pd.notna(row[\"volume_fl_oz\"]) and pd.notna(row[\"count\"]):\n",
    "        continue  # skip filled ones\n",
    "\n",
    "    text = f\"{row.get('specification', '')} {row.get('item_name', '')}\".lower()\n",
    "\n",
    "    # --- Check weight ---\n",
    "    if pd.isna(row[\"weight_oz\"]):\n",
    "        m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(g|kg|mg|lb|ounce|oz)\\b', text)\n",
    "        if m:\n",
    "            val, unit = m.groups()\n",
    "            df.at[idx, \"weight_oz\"] = float(val) * weight_units[unit]\n",
    "\n",
    "    # --- Check volume ---\n",
    "    if pd.isna(row[\"volume_fl_oz\"]):\n",
    "        m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(ml|l|liter|litre|gallon|fl oz|floz)\\b', text)\n",
    "        if m:\n",
    "            val, unit = m.groups()\n",
    "            df.at[idx, \"volume_fl_oz\"] = float(val) * volume_units[unit]\n",
    "\n",
    "    # --- Check count ---\n",
    "    if pd.isna(row[\"count\"]):\n",
    "        m = re.search(r'(?:pack|set|box|pcs|pieces|count|bottles?)\\s*(?:of\\s*)?(\\d+)', text)\n",
    "        if m:\n",
    "            df.at[idx, \"count\"] = float(m.group(1))\n",
    "        else:\n",
    "            # Also handle leading numeric e.g. \"12 pack cookies\"\n",
    "            m2 = re.search(r'(\\d+)\\s*(pack|pcs|pieces|count|bottles?)', text)\n",
    "            if m2:\n",
    "                df.at[idx, \"count\"] = float(m2.group(1))\n",
    "\n",
    "# Fill remaining missing counts as 1 (future-proof way)\n",
    "df[\"count\"] = df[\"count\"].fillna(1)\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ Save updated file\n",
    "# ============================================================\n",
    "output_path = \"test_clean7.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved updated dataset ‚Üí {output_path}\")\n",
    "\n",
    "# Quick stats\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(\"Filled weight_oz:\", df[\"weight_oz\"].notna().sum())\n",
    "print(\"Filled volume_fl_oz:\", df[\"volume_fl_oz\"].notna().sum())\n",
    "print(\"Filled count:\", df[\"count\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a55e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed CSV saved to test_clean8.csv\n",
      "\n",
      "üìä Number of rows under each TYPE:\n",
      "other               : 14492\n",
      "fruits              : 11255\n",
      "tea                 : 10491\n",
      "soft_drink          : 10332\n",
      "juice               : 10138\n",
      "sweets              : 9677\n",
      "spices              : 9061\n",
      "dry_fruits          : 8698\n",
      "milk                : 8107\n",
      "sauces              : 6047\n",
      "coffee              : 5523\n",
      "vegetables          : 4993\n",
      "crispy              : 4619\n",
      "protein_health      : 4609\n",
      "savory              : 4223\n",
      "spicy               : 4019\n",
      "non_veg             : 3617\n",
      "gifts               : 3607\n",
      "cookies             : 3250\n",
      "grains              : 2574\n",
      "cake                : 2502\n",
      "noodles             : 1956\n",
      "\n",
      "üìä Number of rows under each RELATED:\n",
      "soft_drink          : 19813\n",
      "milk                : 19254\n",
      "other               : 17821\n",
      "tea                 : 16375\n",
      "fruits              : 15885\n",
      "juice               : 15717\n",
      "dry_fruits          : 15578\n",
      "spices              : 15325\n",
      "protein_health      : 12947\n",
      "vegetables          : 12573\n",
      "sweets              : 12472\n",
      "coffee              : 9991\n",
      "savory              : 9380\n",
      "gifts               : 9041\n",
      "sauces              : 8861\n",
      "crispy              : 8303\n",
      "non_veg             : 8118\n",
      "spicy               : 6802\n",
      "cookies             : 5852\n",
      "grains              : 5251\n",
      "cake                : 4982\n",
      "noodles             : 3217\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Detailed category dictionary (duplicates merged) ===\n",
    "detailed_categories = {\n",
    "    \"tea\": [\"tea\", \"teabags\", \"oolong\", \"green\", \"herbal\", \"chai\", \"matcha\", \"brewing\", \"yerba\", \"caffeine\"],\n",
    "    \"coffee\": [\"coffee\", \"espresso\", \"arabica\", \"cappuccino\", \"latte\", \"brewing\", \"keurig\"],\n",
    "    \"soft_drink\": [\"soda\", \"cola\", \"sparkling\", \"juice\", \"energy\", \"iced\", \"cold\", \"smoothies\", \"cider\"],\n",
    "    \"juice\": [\"juice\", \"lemonade\", \"orange\", \"apple\", \"fruit\", \"berry\", \"tropical\", \"grape\", \"citrus\"],\n",
    "    \"sweets\": [\"chocolate\", \"candy\", \"chocolates\", \"bars\", \"brownie\", \"lollipops\", \"oreo\", \"toffee\", \"chewy\", \"lollipop\"],\n",
    "    \"cookies\": [\"cookies\", \"biscuit\", \"biscuits\", \"wafer\", \"shortbread\", \"muffin\", \"cupcake\", \"cracker\"],\n",
    "    \"protein_health\": [\"protein\", \"supplement\", \"chia\", \"xylitol\", \"unsweetened\", \"plant\", \"pistachio\", \"superfood\", \"wellness\"],\n",
    "    \"spices\": [\"spice\", \"spices\", \"seasoning\", \"marinades\", \"saffron\", \"cumin\", \"garlic\", \"pepper\", \"herb\", \"curry\", \"seasoned\"],\n",
    "    \"milk\": [\"milk\", \"cream\", \"butter\", \"parmesan\", \"cheese\", \"yogurt\", \"dairy\"],\n",
    "    \"dry_fruits\": [\"nuts\", \"almond\", \"cashews\", \"peanuts\", \"pistachio\", \"trail\", \"mix\", \"seeds\", \"nutty\"],\n",
    "    \"grains\": [\"grains\", \"cereal\", \"oats\", \"semolina\", \"barley\", \"quaker\", \"breakfast\"],\n",
    "    \"noodles\": [\"pasta\", \"noodles\", \"spaghetti\", \"ramen\", \"macaroni\"],\n",
    "    \"cake\": [\"cake\", \"pastry\", \"donut\", \"brownie\", \"cupcake\", \"muffin\"],\n",
    "    \"fruits\": [\"fruit\", \"apple\", \"orange\", \"lemon\", \"berry\", \"banana\", \"grape\", \"strawberry\", \"kiwi\", \"pineapple\", \"mango\"],\n",
    "    \"vegetables\": [\"vegetable\", \"veggies\", \"tomato\", \"onion\", \"corn\", \"potato\", \"broccoli\", \"peppers\"],\n",
    "    \"non_veg\": [\"meat\", \"beef\", \"chicken\", \"pork\", \"turkey\", \"eggs\", \"poultry\", \"bacon\", \"sausage\"],\n",
    "    \"crispy\": [\"chips\", \"crispy\", \"puffs\", \"crisps\", \"snacks\", \"popcorn\"],\n",
    "    \"sauces\": [\"sauce\", \"sauces\", \"ketchup\", \"mustard\", \"vinegar\", \"dressing\", \"salsa\", \"paste\", \"condensed\", \"broth\"],\n",
    "    \"gifts\": [\"gift\", \"multi\", \"canister\", \"party\", \"holiday\", \"christmas\", \"valentine\"],\n",
    "    \"spicy\": [\"spicy\", \"chili\", \"pepper\", \"masala\", \"peri peri\"],\n",
    "    \"savory\": [\"salted\", \"herb\", \"garlic\", \"onion\", \"tangy\"]\n",
    "}\n",
    "\n",
    "# === Function to extract categories ===\n",
    "def extract_types(text):\n",
    "    text = str(text).lower()\n",
    "    matched_types = []\n",
    "    for category, keywords in detailed_categories.items():\n",
    "        for kw in keywords:\n",
    "            if kw in text:\n",
    "                matched_types.append(category)\n",
    "                break\n",
    "    return \" \".join(matched_types) if matched_types else \"other\"\n",
    "\n",
    "# === Main processing function ===\n",
    "def process_csv(input_csv, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # 'type' from item_name\n",
    "    df['type'] = df['item_name'].apply(extract_types)\n",
    "\n",
    "    # 'related' from specification\n",
    "    df['related'] = df['specification'].apply(extract_types)\n",
    "\n",
    "    # Save new CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Processed CSV saved to {output_csv}\")\n",
    "\n",
    "    # Count occurrences for type\n",
    "    type_counts = {}\n",
    "    for types in df['type']:\n",
    "        for t in types.split():\n",
    "            type_counts[t] = type_counts.get(t, 0) + 1\n",
    "\n",
    "    print(\"\\nüìä Number of rows under each TYPE:\")\n",
    "    for t, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{t:20s}: {count}\")\n",
    "\n",
    "    # Count occurrences for related\n",
    "    related_counts = {}\n",
    "    for rels in df['related']:\n",
    "        for r in rels.split():\n",
    "            related_counts[r] = related_counts.get(r, 0) + 1\n",
    "\n",
    "    print(\"\\nüìä Number of rows under each RELATED:\")\n",
    "    for r, count in sorted(related_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{r:20s}: {count}\")\n",
    "\n",
    "# === Usage ===\n",
    "input_csv = \"test_clean7.csv\"\n",
    "output_csv = \"test_clean8.csv\"\n",
    "process_csv(input_csv, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f83715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'nutritional_value' column!\n"
     ]
    }
   ],
   "source": [
    "nutritional_dict = {\n",
    "    \"protein\": [\"protein\", \"whey\", \"soy\", \"lentil\", \"chickpea\", \"egg\", \"meat\", \"milk\"],\n",
    "    \"fiber\": [\"fiber\", \"multigrain\", \"wholegrain\", \"oats\", \"bran\"],\n",
    "    \"sugar\": [\"sugar\", \"sweet\", \"honey\", \"syrup\", \"caramel\", \"candy\", \"chocolate\"],\n",
    "    \"fat\": [\"butter\", \"oil\", \"cheese\", \"ghee\", \"cream\", \"nut\", \"almond\", \"cashew\"],\n",
    "    \"carbs\": [\"rice\", \"pasta\", \"bread\", \"noodle\", \"cereal\", \"corn\", \"flour\"],\n",
    "    \"vitamins\": [\"fortified\", \"enriched\", \"vitamin\", \"omega\", \"probiotic\"],\n",
    "    \"low_sugar\": [\"sugar free\", \"no sugar\", \"zero sugar\"],\n",
    "    \"low_fat\": [\"low fat\", \"fat free\", \"skimmed\"]\n",
    "}\n",
    "df = pd.read_csv(\"test_clean8.csv\")\n",
    "def extract_tags(text, dictionary):\n",
    "    tags = []\n",
    "    text = str(text).lower()\n",
    "    for tag, keywords in dictionary.items():\n",
    "        for kw in keywords:\n",
    "            if kw in text:\n",
    "                tags.append(tag)\n",
    "                break\n",
    "    return \" \".join(tags) if tags else \"\"\n",
    "df[\"nutritional_value\"] = df[\"item_name\"].apply(lambda x: extract_tags(x, nutritional_dict)) + \" \" + \\\n",
    "                          df[\"specification\"].apply(lambda x: extract_tags(x, nutritional_dict))\n",
    "df.to_csv(\"test_clean8.csv\", index=False)\n",
    "\n",
    "print(\"Added 'nutritional_value' column!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bcf4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV with cleaned type column\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Load CSV ===\n",
    "df = pd.read_csv(\"test_clean8.csv\")  # your updated CSV\n",
    "\n",
    "# Replace commas and multiple spaces with single space\n",
    "df['type'] = df['type'].apply(lambda x: re.sub(r'[,\\s]+', ' ', str(x)).strip())\n",
    "df['related'] = df['related'].apply(lambda x: re.sub(r'[,\\s]+', ' ', str(x)).strip())\n",
    "df['nutritional_value'] = df['nutritional_value'].apply(lambda x: re.sub(r'[,\\s]+', ' ', str(x)).strip())\n",
    "\n",
    "# Save the cleaned CSV\n",
    "df.to_csv(\"test_clean8.csv\", index=False)\n",
    "print(\"Saved CSV with cleaned type column\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
